{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alwaysadil/review/blob/main/Copy_of_Adil_Beam_Search_From_the_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "English to telugu language translation from scratch using keras nlp.\n",
        "here spa means telugu not spanish plese note on it\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "sPeB1aDoePpc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNOfCe8fBaBM",
        "outputId": "608f2636-a6bb-41f1-91a9-f16cf5b62bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRMpf_rp4fyv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "outputId": "35b8d5c8-a2ac-40fa-fa39-581175ed3a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.81-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from indic-nlp-library) (1.3.5)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.2.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx-argparse\n",
            "  Downloading sphinx_argparse-0.4.0-py3-none-any.whl (12 kB)\n",
            "Collecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from indic-nlp-library) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->indic-nlp-library) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from sphinx-argparse->indic-nlp-library) (3.5.4)\n",
            "Collecting sphinxcontrib-jquery!=3.0.0,>=2.0.0\n",
            "  Downloading sphinxcontrib_jquery-2.0.0-py3-none-any.whl (3.2 kB)\n",
            "Requirement already satisfied: docutils<0.19 in /usr/local/lib/python3.8/dist-packages (from sphinx-rtd-theme->indic-nlp-library) (0.16)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.15.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (23.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (57.4.0)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.6.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.13)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.25.1)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.3)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.8/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2022.12.7)\n",
            "Installing collected packages: morfessor, sphinxcontrib-jquery, sphinx-rtd-theme, sphinx-argparse, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.81 morfessor-2.0.6 sphinx-argparse-0.4.0 sphinx-rtd-theme-1.2.0 sphinxcontrib-jquery-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os \n",
        "import io\n",
        "import time\n",
        "!pip3 install indic-nlp-library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Fq4jNg0zZMC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1rZGQfKBbAw"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZsMPhxwzeGa"
      },
      "outputs": [],
      "source": [
        "ENCODER_LEN = 100\n",
        "DECODER_LEN = 100\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = BATCH_SIZE*4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rMLS2UNpPgm",
        "outputId": "acfeeeef-9af7-47c3-a747-78390820f343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_nlp\n",
            "  Downloading keras_nlp-0.4.0-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.5/337.5 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (1.4.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (1.21.6)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (15.0.6.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.11.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.51.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (3.19.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (3.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.11.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (57.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (23.1.21)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (2.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (4.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras_nlp) (0.30.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text->keras_nlp) (0.12.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow->keras_nlp) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (2.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (2.25.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (1.8.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras_nlp) (3.2.2)\n",
            "Installing collected packages: tensorflow-text, keras_nlp\n",
            "Successfully installed keras_nlp-0.4.0 tensorflow-text-2.11.0\n"
          ]
        }
      ],
      "source": [
        "pip install keras_nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx0q_6l8pLDz"
      },
      "outputs": [],
      "source": [
        "import keras_nlp\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow_text.tools.wordpiece_vocab import bert_vocab_from_dataset as bert_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ix3zdDKKDro7"
      },
      "outputs": [],
      "source": [
        "def train_word_piece(text_samples, vocab_size, reserved_tokens):\n",
        "    word_piece_ds = tf.data.Dataset.from_tensor_slices(text_samples)\n",
        "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
        "        word_piece_ds.batch(1000).prefetch(2),\n",
        "        vocabulary_size=vocab_size,\n",
        "        reserved_tokens=reserved_tokens,\n",
        "    )\n",
        "    return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99UOXlaeiaUW"
      },
      "outputs": [],
      "source": [
        "with open('/content/37000000_15k_eng_voca.txt') as f:\n",
        "      eng_vocab = f.read().split(\"\\n\")[:-1]\n",
        "with open('/content/37000000_15k_tel_voca.txt') as f:\n",
        "      tel_vocab = f.read().split(\"\\n\")[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_Ih6K7Zp1ay",
        "outputId": "282ff8bd-a184-44bc-a953-631670a053ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Tokens:  ['[PAD]', '[UNK]', '[START]', '[END]', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p']\n",
            "Telugu Tokens:  ['[PAD]', '[UNK]', '[START]', '[END]', 'ఁ', 'ం', 'ః', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ']\n"
          ]
        }
      ],
      "source": [
        "print(\"English Tokens: \", eng_vocab[0:20])\n",
        "print(\"Telugu Tokens: \", tel_vocab[0:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TEvErS-Obfe"
      },
      "outputs": [],
      "source": [
        "eng_tokenizer=[]\n",
        "spa_tokenizer=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pm17nmwqnLV"
      },
      "outputs": [],
      "source": [
        "eng_tokenizer= keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=eng_vocab, lowercase=True\n",
        ")\n",
        "spa_tokenizer= keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=tel_vocab, lowercase=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeGSmIfjFNyW",
        "outputId": "156fcf69-8913-441b-9215-21988d70a3f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English sentence:  maitri\n",
            "Tokens:  tf.Tensor([   4  505  247 1523], shape=(4,), dtype=int32)\n",
            "Recovered text after detokenizing:  tf.Tensor(b'attavarintiki', shape=(), dtype=string)\n",
            "\n",
            "Spanish sentence:  మైత్రి\n",
            "Tokens:  tf.Tensor([  44  162 1651], shape=(3,), dtype=int32)\n",
            "Recovered text after detokenizing:  మైత్రి\n"
          ]
        }
      ],
      "source": [
        "# eng_input_ex = text_pairs[4][0]\n",
        "# eng_tokens_ex = eng_tokenizer.tokenize('attavarintiki')\n",
        "# print(\"English sentence: \", eng_input_ex)\n",
        "# print(\"Tokens: \", eng_tokens_ex)\n",
        "# print(\"Recovered text after detokenizing: \", eng_tokenizer.detokenize(eng_tokens_ex))\n",
        "\n",
        "# print()\n",
        "\n",
        "# spa_input_ex = text_pairs[4][1]\n",
        "# spa_tokens_ex = spa_tokenizer.tokenize(spa_input_ex)\n",
        "# print(\"Spanish sentence: \", spa_input_ex)\n",
        "# print(\"Tokens: \", spa_tokens_ex)\n",
        "# print(\"Recovered text after detokenizing: \", spa_tokenizer.detokenize(spa_tokens_ex).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 1  # This should be at least 10 for convergence\n",
        "MAX_SEQUENCE_LENGTH = 10\n",
        "#ENG_VOCAB_SIZE = 15000\n",
        "#SPA_VOCAB_SIZE = 15000\n",
        "\n",
        "EMBED_DIM = 256\n",
        "INTERMEDIATE_DIM = 2048\n",
        "NUM_HEADS = 8"
      ],
      "metadata": {
        "id": "e4TCCVpgcf0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "264UpASTWM72"
      },
      "outputs": [],
      "source": [
        "def preprocess_batch(eng, spa):\n",
        "    batch_size = tf.shape(spa)[0]\n",
        "\n",
        "    eng = eng_tokenizer(eng)\n",
        "    spa = spa_tokenizer(spa)\n",
        "\n",
        "    # Pad `eng` to `MAX_SEQUENCE_LENGTH`.\n",
        "    eng_start_end_packer = keras_nlp.layers.StartEndPacker(\n",
        "        sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "        pad_value=eng_tokenizer.token_to_id(\"[PAD]\"),\n",
        "    )\n",
        "    eng = eng_start_end_packer(eng)\n",
        "\n",
        "    # Add special tokens (`\"[START]\"` and `\"[END]\"`) to `spa` and pad it as well.\n",
        "    spa_start_end_packer = keras_nlp.layers.StartEndPacker(\n",
        "        sequence_length=MAX_SEQUENCE_LENGTH + 1,\n",
        "        start_value=spa_tokenizer.token_to_id(\"[START]\"),\n",
        "        end_value=spa_tokenizer.token_to_id(\"[END]\"),\n",
        "        pad_value=spa_tokenizer.token_to_id(\"[PAD]\"),\n",
        "    )\n",
        "    spa = spa_start_end_packer(spa)\n",
        "\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": eng,\n",
        "            \"decoder_inputs\": spa[:, :-1],\n",
        "        },\n",
        "        spa[:, 1:],\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/data-to-test.txt') as f:\n",
        "      vocab = f.read().split(\"\\n\")[:-1]\n",
        "\n",
        "\n",
        "def read_text_file(filename):\n",
        "  english_words = []\n",
        "  telugu_words = []\n",
        "  \n",
        "  with open(filename, 'r') as file:\n",
        "    for line in file:\n",
        "      words = line.strip().split()\n",
        "      english_words.append(words[0])\n",
        "      telugu_words.append(words[1])\n",
        "  \n",
        "  return english_words, telugu_words\n",
        "\n",
        "f='/content/data-to-test.txt'\n",
        "english_words, telugu_words = read_text_file(f)\n",
        "whs=[]\n",
        "for i in range(len(english_words)):\n",
        "  whs.append((english_words[i],telugu_words[i]))\n",
        "\n",
        "whatsapp_ds_500=make_dataset(whs)"
      ],
      "metadata": {
        "id": "bJlU_tO368yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9EdZaajsqyU",
        "outputId": "7ad1a90b-5304-4376-cc19-0f289c65aebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 10)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 10)\n",
            "targets.shape: (64, 10)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in whatsapp_ds_500.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    # print(f'inputs[\"decoder2_inputs\"].shape: {inputs[\"decoder2_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import math\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "from keras import constraints\n",
        "from keras import initializers\n",
        "from keras import regularizers\n",
        "from keras.engine.base_layer import Layer\n",
        "from keras.layers import activation\n",
        "from keras.layers import core\n",
        "from keras.layers import regularization\n",
        "from keras.utils import tf_utils\n",
        "\n",
        "from tensorflow.python.platform import tf_logging as logging\n",
        "from tensorflow.python.util.tf_export import keras_export\n",
        "\n",
        "_CHR_IDX = string.ascii_lowercase\n",
        "\n",
        "\n",
        "def _build_attention_equation(rank, attn_axes):\n",
        " \n",
        "    target_notation = _CHR_IDX[:rank]\n",
        "    # `batch_dims` includes the head dim.\n",
        "    batch_dims = tuple(np.delete(range(rank), attn_axes + (rank - 1,)))\n",
        "    letter_offset = rank\n",
        "    source_notation = \"\"\n",
        "    for i in range(rank):\n",
        "        if i in batch_dims or i == rank - 1:\n",
        "            source_notation += target_notation[i]\n",
        "        else:\n",
        "            source_notation += _CHR_IDX[letter_offset]\n",
        "            letter_offset += 1\n",
        "\n",
        "    product_notation = \"\".join(\n",
        "        [target_notation[i] for i in batch_dims]\n",
        "        + [target_notation[i] for i in attn_axes]\n",
        "        + [source_notation[i] for i in attn_axes]\n",
        "    )\n",
        "    dot_product_equation = \"%s,%s->%s\" % (\n",
        "        source_notation,\n",
        "        target_notation,\n",
        "        product_notation,\n",
        "    )\n",
        "    attn_scores_rank = len(product_notation)\n",
        "    combine_equation = \"%s,%s->%s\" % (\n",
        "        product_notation,\n",
        "        source_notation,\n",
        "        target_notation,\n",
        "    )\n",
        "    return dot_product_equation, combine_equation, attn_scores_rank\n",
        "\n",
        "\n",
        "def _build_proj_equation(free_dims, bound_dims, output_dims):\n",
        "    \"\"\"Builds an einsum equation for projections inside multi-head attention.\"\"\"\n",
        "    input_str = \"\"\n",
        "    kernel_str = \"\"\n",
        "    output_str = \"\"\n",
        "    bias_axes = \"\"\n",
        "    letter_offset = 0\n",
        "    for i in range(free_dims):\n",
        "        char = _CHR_IDX[i + letter_offset]\n",
        "        input_str += char\n",
        "        output_str += char\n",
        "\n",
        "    letter_offset += free_dims\n",
        "    for i in range(bound_dims):\n",
        "        char = _CHR_IDX[i + letter_offset]\n",
        "        input_str += char\n",
        "        kernel_str += char\n",
        "\n",
        "    letter_offset += bound_dims\n",
        "    for i in range(output_dims):\n",
        "        char = _CHR_IDX[i + letter_offset]\n",
        "        kernel_str += char\n",
        "        output_str += char\n",
        "        bias_axes += char\n",
        "    equation = f\"{input_str},{kernel_str}->{output_str}\"\n",
        "\n",
        "    return equation, bias_axes, len(output_str)\n",
        "\n",
        "\n",
        "def _get_output_shape(output_rank, known_last_dims):\n",
        "    return [None] * (output_rank - len(known_last_dims)) + list(known_last_dims)\n",
        "\n",
        "\n",
        "@keras_export(\"keras.layers.MultiHeadAttention\")\n",
        "class MultiHeadAttention(Layer):\n",
        "\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_heads,\n",
        "        key_dim,\n",
        "        value_dim=None,\n",
        "        dropout=0.0,\n",
        "        use_bias=True,\n",
        "        output_shape=None,\n",
        "        attention_axes=None,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        activity_regularizer=None,\n",
        "        kernel_constraint=None,\n",
        "        bias_constraint=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self._num_heads = num_heads\n",
        "        self._key_dim = key_dim\n",
        "        self._value_dim = value_dim if value_dim else key_dim\n",
        "        self._dropout = dropout\n",
        "        self._use_bias = use_bias\n",
        "        self._output_shape = output_shape\n",
        "        self._kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self._bias_initializer = initializers.get(bias_initializer)\n",
        "        self._kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self._bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self._activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self._kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self._bias_constraint = constraints.get(bias_constraint)\n",
        "        if attention_axes is not None and not isinstance(\n",
        "            attention_axes, collections.abc.Sized\n",
        "        ):\n",
        "            self._attention_axes = (attention_axes,)\n",
        "        else:\n",
        "            self._attention_axes = attention_axes\n",
        "        self._built_from_signature = False\n",
        "        self._query_shape, self._key_shape, self._value_shape = None, None, None\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            \"num_heads\": self._num_heads,\n",
        "            \"key_dim\": self._key_dim,\n",
        "            \"value_dim\": self._value_dim,\n",
        "            \"dropout\": self._dropout,\n",
        "            \"use_bias\": self._use_bias,\n",
        "            \"output_shape\": self._output_shape,\n",
        "            \"attention_axes\": self._attention_axes,\n",
        "            \"kernel_initializer\": initializers.serialize(\n",
        "                self._kernel_initializer\n",
        "            ),\n",
        "            \"bias_initializer\": initializers.serialize(self._bias_initializer),\n",
        "            \"kernel_regularizer\": regularizers.serialize(\n",
        "                self._kernel_regularizer\n",
        "            ),\n",
        "            \"bias_regularizer\": regularizers.serialize(self._bias_regularizer),\n",
        "            \"activity_regularizer\": regularizers.serialize(\n",
        "                self._activity_regularizer\n",
        "            ),\n",
        "            \"kernel_constraint\": constraints.serialize(self._kernel_constraint),\n",
        "            \"bias_constraint\": constraints.serialize(self._bias_constraint),\n",
        "            \"query_shape\": self._query_shape,\n",
        "            \"key_shape\": self._key_shape,\n",
        "            \"value_shape\": self._value_shape,\n",
        "        }\n",
        "        base_config = super().get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        # If the layer has a different build() function from the Keras default,\n",
        "        # we need to trigger the customized build to create weights.\n",
        "        query_shape = config.pop(\"query_shape\")\n",
        "        key_shape = config.pop(\"key_shape\")\n",
        "        value_shape = config.pop(\"value_shape\")\n",
        "        layer = cls(**config)\n",
        "        if None in [query_shape, key_shape, value_shape]:\n",
        "            logging.warning(\n",
        "                \"One of dimensions of the input shape is missing. It \"\n",
        "                \"should have been memorized when the layer was serialized. \"\n",
        "                \"%s is created without weights.\",\n",
        "                str(cls),\n",
        "            )\n",
        "        else:\n",
        "            layer._build_from_signature(query_shape, value_shape, key_shape)\n",
        "        return layer\n",
        "\n",
        "    def _build_from_signature(self, query, value, key=None):\n",
        "        \"\"\"Builds layers and variables.\n",
        "\n",
        "        Once the method is called, self._built_from_signature will be set to\n",
        "        True.\n",
        "\n",
        "        Args:\n",
        "          query: Query tensor or TensorShape.\n",
        "          value: Value tensor or TensorShape.\n",
        "          key: Key tensor or TensorShape.\n",
        "        \"\"\"\n",
        "        self._built_from_signature = True\n",
        "        if hasattr(query, \"shape\"):\n",
        "            self._query_shape = tf.TensorShape(query.shape)\n",
        "        else:\n",
        "            self._query_shape = tf.TensorShape(query)\n",
        "        if hasattr(value, \"shape\"):\n",
        "            self._value_shape = tf.TensorShape(value.shape)\n",
        "        else:\n",
        "            self._value_shape = tf.TensorShape(value)\n",
        "        if key is None:\n",
        "            self._key_shape = self._value_shape\n",
        "        elif hasattr(key, \"shape\"):\n",
        "            self._key_shape = tf.TensorShape(key.shape)\n",
        "        else:\n",
        "            self._key_shape = tf.TensorShape(key)\n",
        "\n",
        "        # Any setup work performed only once should happen in an `init_scope`\n",
        "        # to avoid creating symbolic Tensors that will later pollute any eager\n",
        "        # operations.\n",
        "        with tf_utils.maybe_init_scope(self):\n",
        "            free_dims = self._query_shape.rank - 1\n",
        "            einsum_equation, bias_axes, output_rank = _build_proj_equation(\n",
        "                free_dims, bound_dims=1, output_dims=2\n",
        "            )\n",
        "            self._query_dense = core.EinsumDense(\n",
        "                einsum_equation,\n",
        "                output_shape=_get_output_shape(\n",
        "                    output_rank - 1, [self._num_heads, self._key_dim]\n",
        "                ),\n",
        "                bias_axes=bias_axes if self._use_bias else None,\n",
        "                name=\"query\",\n",
        "                **self._get_common_kwargs_for_sublayer(),\n",
        "            )\n",
        "            einsum_equation, bias_axes, output_rank = _build_proj_equation(\n",
        "                self._key_shape.rank - 1, bound_dims=1, output_dims=2\n",
        "            )\n",
        "            self._key_dense = core.EinsumDense(\n",
        "                einsum_equation,\n",
        "                output_shape=_get_output_shape(\n",
        "                    output_rank - 1, [self._num_heads, self._key_dim]\n",
        "                ),\n",
        "                bias_axes=bias_axes if self._use_bias else None,\n",
        "                name=\"key\",\n",
        "                **self._get_common_kwargs_for_sublayer(),\n",
        "            )\n",
        "            einsum_equation, bias_axes, output_rank = _build_proj_equation(\n",
        "                self._value_shape.rank - 1, bound_dims=1, output_dims=2\n",
        "            )\n",
        "            self._value_dense = core.EinsumDense(\n",
        "                einsum_equation,\n",
        "                output_shape=_get_output_shape(\n",
        "                    output_rank - 1, [self._num_heads, self._value_dim]\n",
        "                ),\n",
        "                bias_axes=bias_axes if self._use_bias else None,\n",
        "                name=\"value\",\n",
        "                **self._get_common_kwargs_for_sublayer(),\n",
        "            )\n",
        "\n",
        "            # Builds the attention computations for multi-head dot product\n",
        "            # attention.  These computations could be wrapped into the keras\n",
        "            # attention layer once it supports mult-head einsum computations.\n",
        "            self._build_attention(output_rank)\n",
        "            self._output_dense = self._make_output_dense(\n",
        "                free_dims,\n",
        "                self._get_common_kwargs_for_sublayer(),\n",
        "                \"attention_output\",\n",
        "            )\n",
        "\n",
        "    def _get_common_kwargs_for_sublayer(self):\n",
        "        common_kwargs = dict(\n",
        "            kernel_regularizer=self._kernel_regularizer,\n",
        "            bias_regularizer=self._bias_regularizer,\n",
        "            activity_regularizer=self._activity_regularizer,\n",
        "            kernel_constraint=self._kernel_constraint,\n",
        "            bias_constraint=self._bias_constraint,\n",
        "        )\n",
        "        # Create new clone of kernel/bias initializer, so that we don't reuse\n",
        "        # the initializer instance, which could lead to same init value since\n",
        "        # initializer is stateless.\n",
        "        kernel_initializer = self._kernel_initializer.__class__.from_config(\n",
        "            self._kernel_initializer.get_config()\n",
        "        )\n",
        "        bias_initializer = self._bias_initializer.__class__.from_config(\n",
        "            self._bias_initializer.get_config()\n",
        "        )\n",
        "        common_kwargs[\"kernel_initializer\"] = kernel_initializer\n",
        "        common_kwargs[\"bias_initializer\"] = bias_initializer\n",
        "        return common_kwargs\n",
        "\n",
        "    def _make_output_dense(self, free_dims, common_kwargs, name=None):\n",
        "\n",
        "        if self._output_shape:\n",
        "            if not isinstance(self._output_shape, collections.abc.Sized):\n",
        "                output_shape = [self._output_shape]\n",
        "            else:\n",
        "                output_shape = self._output_shape\n",
        "        else:\n",
        "            output_shape = [self._query_shape[-1]]\n",
        "        einsum_equation, bias_axes, output_rank = _build_proj_equation(\n",
        "            free_dims, bound_dims=2, output_dims=len(output_shape)\n",
        "        )\n",
        "        return core.EinsumDense(\n",
        "            einsum_equation,\n",
        "            output_shape=_get_output_shape(output_rank - 1, output_shape),\n",
        "            bias_axes=bias_axes if self._use_bias else None,\n",
        "            name=name,\n",
        "            **common_kwargs,\n",
        "        )\n",
        "\n",
        "    def _build_attention(self, rank):\n",
        "        \"\"\"Builds multi-head dot-product attention computations.\n",
        "\n",
        "        This function builds attributes necessary for `_compute_attention` to\n",
        "        customize attention computation to replace the default dot-product\n",
        "        attention.\n",
        "\n",
        "        Args:\n",
        "          rank: the rank of query, key, value tensors.\n",
        "        \"\"\"\n",
        "        if self._attention_axes is None:\n",
        "            self._attention_axes = tuple(range(1, rank - 2))\n",
        "        else:\n",
        "            self._attention_axes = tuple(self._attention_axes)\n",
        "        (\n",
        "            self._dot_product_equation,\n",
        "            self._combine_equation,\n",
        "            attn_scores_rank,\n",
        "        ) = _build_attention_equation(rank, attn_axes=self._attention_axes)\n",
        "        norm_axes = tuple(\n",
        "            range(\n",
        "                attn_scores_rank - len(self._attention_axes), attn_scores_rank\n",
        "            )\n",
        "        )\n",
        "        self._softmax = activation.Softmax(axis=norm_axes)\n",
        "        self._dropout_layer = regularization.Dropout(rate=self._dropout)\n",
        "\n",
        "    def _masked_softmax(self, attention_scores, attention_mask=None):\n",
        "        # Normalize the attention scores to probabilities.\n",
        "        # `attention_scores` = [B, N, T, S]\n",
        "        if attention_mask is not None:\n",
        "            # The expand dim happens starting from the `num_heads` dimension,\n",
        "            # (<batch_dims>, num_heads, <query_attention_dims,\n",
        "            # key_attention_dims>)\n",
        "            mask_expansion_axis = -len(self._attention_axes) * 2 - 1\n",
        "            for _ in range(\n",
        "                len(attention_scores.shape) - len(attention_mask.shape)\n",
        "            ):\n",
        "                attention_mask = tf.expand_dims(\n",
        "                    attention_mask, axis=mask_expansion_axis\n",
        "                )\n",
        "        return self._softmax(attention_scores, attention_mask)\n",
        "\n",
        "    def _compute_attention(\n",
        "        self, query, key, value, attention_mask=None, training=None\n",
        "    ):\n",
        "        \n",
        "        # Note: Applying scalar multiply at the smaller end of einsum improves\n",
        "        # XLA performance, but may introduce slight numeric differences in\n",
        "        # the Transformer attention head.\n",
        "        query = tf.multiply(query, 1.0 / math.sqrt(float(self._key_dim)))\n",
        "\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw\n",
        "        # attention scores.\n",
        "        attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
        "\n",
        "        attention_scores = self._masked_softmax(\n",
        "            attention_scores, attention_mask\n",
        "        )\n",
        "\n",
        "        # This is actually dropping out entire tokens to attend to, which might\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
        "        attention_scores_dropout = self._dropout_layer(\n",
        "            attention_scores, training=training\n",
        "        )\n",
        "\n",
        "        # `context_layer` = [B, T, N, H]\n",
        "        attention_output = tf.einsum(\n",
        "            self._combine_equation, attention_scores_dropout, value\n",
        "        )\n",
        "        return attention_output, attention_scores\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        query,\n",
        "        value,\n",
        "        key=None,\n",
        "        attention_mask=None,\n",
        "        return_attention_scores=False,\n",
        "        training=None,\n",
        "        use_causal_mask=False,\n",
        "    ):\n",
        "        attention_mask = self._compute_attention_mask(\n",
        "            query,\n",
        "            value,\n",
        "            key=key,\n",
        "            attention_mask=attention_mask,\n",
        "            use_causal_mask=use_causal_mask,\n",
        "        )\n",
        "\n",
        "        if not self._built_from_signature:\n",
        "            self._build_from_signature(query=query, value=value, key=key)\n",
        "        if key is None:\n",
        "            key = value\n",
        "\n",
        "        query_is_ragged = isinstance(query, tf.RaggedTensor)\n",
        "        if query_is_ragged:\n",
        "            query_lengths = query.nested_row_lengths()\n",
        "            query = query.to_tensor()\n",
        "\n",
        "        key_is_ragged = isinstance(key, tf.RaggedTensor)\n",
        "        value_is_ragged = isinstance(value, tf.RaggedTensor)\n",
        "        if key_is_ragged and value_is_ragged:\n",
        "            # Ensure they have the same shape.\n",
        "            bounding_shape = tf.math.maximum(\n",
        "                key.bounding_shape(), value.bounding_shape()\n",
        "            )\n",
        "            key = key.to_tensor(shape=bounding_shape)\n",
        "            value = value.to_tensor(shape=bounding_shape)\n",
        "        elif key_is_ragged:\n",
        "            key = key.to_tensor(shape=tf.shape(value))\n",
        "        elif value_is_ragged:\n",
        "            value = value.to_tensor(shape=tf.shape(key))\n",
        "\n",
        "        #   N = `num_attention_heads`\n",
        "        #   H = `size_per_head`\n",
        "        # `query` = [B, T, N ,H]\n",
        "        query = self._query_dense(query)\n",
        "\n",
        "        # `key` = [B, S, N, H]\n",
        "        key = self._key_dense(key)\n",
        "\n",
        "        # `value` = [B, S, N, H]\n",
        "        value = self._value_dense(value)\n",
        "\n",
        "        attention_output, attention_scores = self._compute_attention(\n",
        "            query, key, value, attention_mask, training\n",
        "        )\n",
        "        attention_output = self._output_dense(attention_output)\n",
        "\n",
        "        if query_is_ragged:\n",
        "            attention_output = tf.RaggedTensor.from_tensor(\n",
        "                attention_output, lengths=query_lengths\n",
        "            )\n",
        "\n",
        "        if return_attention_scores:\n",
        "            return attention_output, attention_scores\n",
        "        return attention_output\n",
        "\n",
        "    def _compute_attention_mask(\n",
        "        self, query, value, key=None, attention_mask=None, use_causal_mask=False\n",
        "    ):\n",
        " \n",
        "        query_mask = getattr(query, \"_keras_mask\", None)\n",
        "        value_mask = getattr(value, \"_keras_mask\", None)\n",
        "        key_mask = getattr(key, \"_keras_mask\", None)\n",
        "        auto_mask = None\n",
        "        if query_mask is not None:\n",
        "            query_mask = tf.cast(query_mask, tf.bool)  # defensive casting\n",
        "            # B = batch size, T = max query length\n",
        "            auto_mask = query_mask[:, :, tf.newaxis]  # shape is [B, T, 1]\n",
        "        if value_mask is not None:\n",
        "            value_mask = tf.cast(value_mask, tf.bool)  # defensive casting\n",
        "            # B = batch size, S == max value length\n",
        "            mask = value_mask[:, tf.newaxis, :]  # shape is [B, 1, S]\n",
        "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
        "        if key_mask is not None:\n",
        "            key_mask = tf.cast(key_mask, tf.bool)  # defensive casting\n",
        "            # B == batch size, S == max key length == max value length\n",
        "            mask = key_mask[:, tf.newaxis, :]  # shape is [B, 1, S]\n",
        "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
        "        if use_causal_mask:\n",
        "            # the shape of the causal mask is [1, T, S]\n",
        "            mask = self._compute_causal_mask(query, value)\n",
        "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
        "        if auto_mask is not None:\n",
        "            # merge attention_mask & automatic mask, to shape [B, T, S]\n",
        "            attention_mask = (\n",
        "                auto_mask\n",
        "                if attention_mask is None\n",
        "                else tf.cast(attention_mask, bool) & auto_mask\n",
        "            )\n",
        "        return attention_mask\n",
        "\n",
        "    def _compute_causal_mask(self, query, value=None):\n",
        "       \n",
        "        q_seq_length = tf.shape(query)[1]\n",
        "        v_seq_length = q_seq_length if value is None else tf.shape(value)[1]\n",
        "        return tf.linalg.band_part(  # creates a lower triangular matrix\n",
        "            tf.ones((1, q_seq_length, v_seq_length), tf.bool), -1, 0\n",
        "        )\n",
        "\n",
        "    def compute_output_shape(self, query_shape, value_shape, key_shape=None):\n",
        "\n",
        "        if key_shape is None:\n",
        "            key_shape = value_shape\n",
        "\n",
        "        query_shape = tf.TensorShape(query_shape)\n",
        "        value_shape = tf.TensorShape(value_shape)\n",
        "        key_shape = tf.TensorShape(key_shape)\n",
        "\n",
        "        if query_shape[-1] != value_shape[-1]:\n",
        "            raise ValueError(\n",
        "                \"The last dimension of `query_shape` and `value_shape` \"\n",
        "                f\"must be equal, but are {query_shape[-1]}, {value_shape[-1]}. \"\n",
        "                \"Received: query_shape={query_shape}, value_shape={value_shape}\"\n",
        "            )\n",
        "\n",
        "        if value_shape[1:-1] != key_shape[1:-1]:\n",
        "            raise ValueError(\n",
        "                \"All dimensions of `value` and `key`, except the last one, \"\n",
        "                f\"must be equal. Received {value_shape} and \"\n",
        "                f\"{key_shape}\"\n",
        "            )\n",
        "\n",
        "        if self._output_shape:\n",
        "            return query_shape[:-1].concatenate(self._output_shape)\n",
        "\n",
        "        return query_shape"
      ],
      "metadata": {
        "id": "nNhF7ukyc5io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Encoder\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"encoder_inputs\")\n",
        "import keras_nlp.layers\n",
        "from tensorflow import keras\n",
        "from keras_nlp.utils.keras_utils import clone_initializer\n",
        "\n",
        "class TokenAndPositionEmbedding(keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocabulary_size,\n",
        "        sequence_length,\n",
        "        embedding_dim,\n",
        "        embeddings_initializer=\"glorot_uniform\",\n",
        "        mask_zero=False,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        if vocabulary_size is None:\n",
        "            raise ValueError(\n",
        "                \"`vocabulary_size` must be an Integer, received `None`.\"\n",
        "            )\n",
        "        if sequence_length is None:\n",
        "            raise ValueError(\n",
        "                \"`sequence_length` must be an Integer, received `None`.\"\n",
        "            )\n",
        "        if embedding_dim is None:\n",
        "            raise ValueError(\n",
        "                \"`embedding_dim` must be an Integer, received `None`.\"\n",
        "            )\n",
        "        self.vocabulary_size = int(vocabulary_size)\n",
        "        self.sequence_length = int(sequence_length)\n",
        "        self.embedding_dim = int(embedding_dim)\n",
        "        self.embeddings_initializer = keras.initializers.get(\n",
        "            embeddings_initializer\n",
        "        )\n",
        "        self.token_embedding = keras.layers.Embedding(\n",
        "            vocabulary_size,\n",
        "            embedding_dim,\n",
        "            embeddings_initializer=clone_initializer(\n",
        "                self.embeddings_initializer\n",
        "            ),\n",
        "            mask_zero=mask_zero,\n",
        "            name=\"token_embedding\"\n",
        "            + str(keras.backend.get_uid(\"token_embedding\")),\n",
        "        )\n",
        "        self.position_embedding = keras_nlp.layers.PositionEmbedding(\n",
        "            sequence_length=sequence_length,\n",
        "            initializer=clone_initializer(self.embeddings_initializer),\n",
        "            name=\"position_embedding\"\n",
        "            + str(keras.backend.get_uid(\"position_embedding\")),\n",
        "        )\n",
        "        self.supports_masking = self.token_embedding.supports_masking\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"vocabulary_size\": self.vocabulary_size,\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"embedding_dim\": self.embedding_dim,\n",
        "                \"embeddings_initializer\": keras.initializers.serialize(\n",
        "                    self.embeddings_initializer\n",
        "                ),\n",
        "                \"mask_zero\": self.token_embedding.mask_zero,\n",
        "            },\n",
        "        )\n",
        "        return config\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embedded_tokens = self.token_embedding(inputs)\n",
        "        embedded_positions = self.position_embedding(embedded_tokens)\n",
        "        outputs = embedded_tokens + embedded_positions\n",
        "        return outputs\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return self.token_embedding.compute_mask(inputs, mask=mask)\n",
        "\n",
        "keras.utils.get_custom_objects()[\"TokenAndPositionEmbedding\"] = TokenAndPositionEmbedding\n",
        "\n",
        "x = TokenAndPositionEmbedding(\n",
        "    vocabulary_size=len(eng_vocab),\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(encoder_inputs)\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras_nlp.layers.transformer_layer_utils import (  # isort:skip\n",
        "    merge_padding_and_attention_mask,\n",
        ")\n",
        "\n",
        "\n",
        "class TransformerEncoder(keras.layers.Layer):\n",
        "\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        intermediate_dim,\n",
        "        num_heads,\n",
        "        dropout=0,\n",
        "        activation=\"relu\",\n",
        "        layer_norm_epsilon=1e-05,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        name=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.intermediate_dim = intermediate_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.layer_norm_epsilon = layer_norm_epsilon\n",
        "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
        "        self._built = False\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def _build(self, input_shape):\n",
        "        # Create layers based on input shape.\n",
        "        self._built = True\n",
        "        feature_size = input_shape[-1]\n",
        "        self._attention_head_size = int(feature_size // self.num_heads)\n",
        "        self._multi_head_attention_layer =MultiHeadAttention(\n",
        "            num_heads=self.num_heads,\n",
        "            key_dim=self._attention_head_size,\n",
        "            value_dim=self._attention_head_size,\n",
        "            dropout=self.dropout,\n",
        "            kernel_initializer=self.kernel_initializer,\n",
        "            bias_initializer=self.bias_initializer,\n",
        "        )\n",
        "\n",
        "        self._attention_layernorm = keras.layers.LayerNormalization(\n",
        "            epsilon=self.layer_norm_epsilon,\n",
        "        )\n",
        "        self._feedforward_layernorm = keras.layers.LayerNormalization(\n",
        "            epsilon=self.layer_norm_epsilon,\n",
        "        )\n",
        "\n",
        "        self._attention_dropout = keras.layers.Dropout(rate=self.dropout)\n",
        "\n",
        "        self._intermediate_dense = keras.layers.Dense(\n",
        "            self.intermediate_dim,\n",
        "            activation=self.activation,\n",
        "            kernel_initializer=self.kernel_initializer,\n",
        "            bias_initializer=self.bias_initializer,\n",
        "        )\n",
        "        self._output_dense = keras.layers.Dense(\n",
        "            feature_size,\n",
        "            kernel_initializer=self.kernel_initializer,\n",
        "            bias_initializer=self.bias_initializer,\n",
        "        )\n",
        "        self._output_dropout = keras.layers.Dropout(rate=self.dropout)\n",
        "\n",
        "    def _add_and_norm(self, input1, input2, norm_layer):\n",
        "        return norm_layer(input1 + input2)\n",
        "\n",
        "    def _feed_forward(self, input):\n",
        "        x = self._intermediate_dense(input)\n",
        "        x = self._output_dense(x)\n",
        "        return self._output_dropout(x)\n",
        "\n",
        "    def call(self, inputs, padding_mask=None, attention_mask=None):\n",
        "\n",
        "        if not self._built:\n",
        "            self._build(inputs.shape)\n",
        "\n",
        "        mask = merge_padding_and_attention_mask(\n",
        "            inputs,\n",
        "            padding_mask,\n",
        "            attention_mask,\n",
        "        )\n",
        "\n",
        "        # Self attention.\n",
        "        attended = self._multi_head_attention_layer(\n",
        "            inputs, inputs, inputs, attention_mask=mask\n",
        "        )\n",
        "        attended = self._attention_dropout(attended)\n",
        "        attended = self._add_and_norm(\n",
        "            inputs,\n",
        "            attended,\n",
        "            self._attention_layernorm,\n",
        "        )\n",
        "        # Feedforward.\n",
        "        feed_forward_output = self._feed_forward(attended)\n",
        "        return self._add_and_norm(\n",
        "            attended, feed_forward_output, self._feedforward_layernorm\n",
        "        )\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"intermediate_dim\": self.intermediate_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "                \"dropout\": self.dropout,\n",
        "                \"activation\": keras.activations.serialize(self.activation),\n",
        "                \"layer_norm_epsilon\": self.layer_norm_epsilon,\n",
        "                \"kernel_initializer\": keras.initializers.serialize(\n",
        "                    self.kernel_initializer\n",
        "                ),\n",
        "                \"bias_initializer\": keras.initializers.serialize(\n",
        "                    self.bias_initializer\n",
        "                ),\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "encoder_outputs = TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n"
      ],
      "metadata": {
        "id": "eObBAXpAh8n5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d972b8cf-3345-4c29-e767-03bbb6b8b2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Decoder\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\")\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "import keras_nlp.layers\n",
        "from keras_nlp.utils.keras_utils import clone_initializer\n",
        "\n",
        "\n",
        "class TokenAndPositionEmbedding(keras.layers.Layer):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocabulary_size,\n",
        "        sequence_length,\n",
        "        embedding_dim,\n",
        "        embeddings_initializer=\"glorot_uniform\",\n",
        "        mask_zero=False,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        if vocabulary_size is None:\n",
        "            raise ValueError(\n",
        "                \"`vocabulary_size` must be an Integer, received `None`.\"\n",
        "            )\n",
        "        if sequence_length is None:\n",
        "            raise ValueError(\n",
        "                \"`sequence_length` must be an Integer, received `None`.\"\n",
        "            )\n",
        "        if embedding_dim is None:\n",
        "            raise ValueError(\n",
        "                \"`embedding_dim` must be an Integer, received `None`.\"\n",
        "            )\n",
        "        self.vocabulary_size = int(vocabulary_size)\n",
        "        self.sequence_length = int(sequence_length)\n",
        "        self.embedding_dim = int(embedding_dim)\n",
        "        self.embeddings_initializer = keras.initializers.get(\n",
        "            embeddings_initializer\n",
        "        )\n",
        "        self.token_embedding = keras.layers.Embedding(\n",
        "            vocabulary_size,\n",
        "            embedding_dim,\n",
        "            embeddings_initializer=clone_initializer(\n",
        "                self.embeddings_initializer\n",
        "            ),\n",
        "            mask_zero=mask_zero,\n",
        "            name=\"token_embedding\"\n",
        "            + str(keras.backend.get_uid(\"token_embedding\")),\n",
        "        )\n",
        "        self.position_embedding = keras_nlp.layers.PositionEmbedding(\n",
        "            sequence_length=sequence_length,\n",
        "            initializer=clone_initializer(self.embeddings_initializer),\n",
        "            name=\"position_embedding\"\n",
        "            + str(keras.backend.get_uid(\"position_embedding\")),\n",
        "        )\n",
        "        self.supports_masking = self.token_embedding.supports_masking\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"vocabulary_size\": self.vocabulary_size,\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"embedding_dim\": self.embedding_dim,\n",
        "                \"embeddings_initializer\": keras.initializers.serialize(\n",
        "                    self.embeddings_initializer\n",
        "                ),\n",
        "                \"mask_zero\": self.token_embedding.mask_zero,\n",
        "            },\n",
        "        )\n",
        "        return config\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embedded_tokens = self.token_embedding(inputs)\n",
        "        embedded_positions = self.position_embedding(embedded_tokens)\n",
        "        outputs = embedded_tokens + embedded_positions\n",
        "        return outputs\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return self.token_embedding.compute_mask(inputs, mask=mask)\n",
        "\n",
        "\n",
        "x =TokenAndPositionEmbedding(\n",
        "    vocabulary_size=len(tel_vocab),\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")(decoder_inputs)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras_nlp.layers.transformer_layer_utils import (  # isort:skip\n",
        "    compute_causal_mask,\n",
        "    merge_padding_and_attention_mask,\n",
        ")\n",
        "\n",
        "\n",
        "class TransformerDecoder(keras.layers.Layer):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        intermediate_dim,\n",
        "        num_heads,\n",
        "        dropout=0,\n",
        "        activation=\"relu\",\n",
        "        layer_norm_epsilon=1e-05,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        name=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.intermediate_dim = intermediate_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.layer_norm_epsilon = layer_norm_epsilon\n",
        "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
        "        self._built = False\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def _build(self, input_shape, include_cross_attention):\n",
        "        # Create layers based on input shape.\n",
        "        self._built = True\n",
        "        feature_size = input_shape[-1]\n",
        "        self._attention_head_size = int(feature_size // self.num_heads)\n",
        "        self._self_attention_layer =MultiHeadAttention(\n",
        "            num_heads=self.num_heads,\n",
        "            key_dim=self._attention_head_size,\n",
        "            value_dim=self._attention_head_size,\n",
        "            dropout=self.dropout,\n",
        "            kernel_initializer=self.kernel_initializer,\n",
        "            bias_initializer=self.bias_initializer,\n",
        "        )\n",
        "\n",
        "        self._decoder_attention_layernorm = keras.layers.LayerNormalization(\n",
        "            epsilon=self.layer_norm_epsilon,\n",
        "        )\n",
        "\n",
        "        self._cross_attention_layer = None\n",
        "        if include_cross_attention:\n",
        "            # Create layers for cross attention.\n",
        "            self._cross_attention_layer =MultiHeadAttention(\n",
        "                num_heads=self.num_heads,\n",
        "                key_dim=self._attention_head_size,\n",
        "                value_dim=feature_size,\n",
        "                dropout=self.dropout,\n",
        "                kernel_initializer=self.kernel_initializer,\n",
        "                bias_initializer=self.bias_initializer,\n",
        "            )\n",
        "\n",
        "            self._cross_attention_layernorm = keras.layers.LayerNormalization(\n",
        "                epsilon=self.layer_norm_epsilon,\n",
        "            )\n",
        "\n",
        "            self._cross_attention_dropout = keras.layers.Dropout(\n",
        "                rate=self.dropout,\n",
        "            )\n",
        "\n",
        "        self._feedforward_layernorm = keras.layers.LayerNormalization(\n",
        "            epsilon=self.layer_norm_epsilon,\n",
        "        )\n",
        "\n",
        "        self._self_attention_dropout = keras.layers.Dropout(rate=self.dropout)\n",
        "\n",
        "        # First dense layer in the feedforward network, which maps input\n",
        "        # feauture size to dimension `self.intermediate_dim`.\n",
        "        self._intermediate_dense = keras.layers.Dense(\n",
        "            self.intermediate_dim,\n",
        "            activation=self.activation,\n",
        "            kernel_initializer=self.kernel_initializer,\n",
        "            bias_initializer=self.bias_initializer,\n",
        "        )\n",
        "        # Second dense layer in the feedforward network, which maps input\n",
        "        # feature size back to the input feature size.\n",
        "        self._output_dense = keras.layers.Dense(\n",
        "            feature_size,\n",
        "            kernel_initializer=self.kernel_initializer,\n",
        "            bias_initializer=self.bias_initializer,\n",
        "        )\n",
        "        self._output_dropout = keras.layers.Dropout(rate=self.dropout)\n",
        "\n",
        "    def _add_and_norm(self, input1, input2, norm_layer):\n",
        "        return norm_layer(input1 + input2)\n",
        "\n",
        "    def _feed_forward(self, input):\n",
        "        x = self._intermediate_dense(input)\n",
        "        x = self._output_dense(x)\n",
        "        return self._output_dropout(x)\n",
        "\n",
        "    def call(\n",
        "        self,\n",
        "        decoder_sequence,\n",
        "        encoder_sequence=None,\n",
        "        decoder_padding_mask=None,\n",
        "        decoder_attention_mask=None,\n",
        "        encoder_padding_mask=None,\n",
        "        encoder_attention_mask=None,\n",
        "    ):\n",
        "\n",
        "        has_encoder_sequence = encoder_sequence is not None\n",
        "        if not self._built:\n",
        "            self._build(decoder_sequence.shape, has_encoder_sequence)\n",
        "\n",
        "        is_cross_attention = self._cross_attention_layer is not None\n",
        "        if not is_cross_attention and has_encoder_sequence:\n",
        "            raise ValueError(\n",
        "                \"The number of call arguments to \"\n",
        "                \"`keras_nlp.layers.TransformerDecoder` should not change. \"\n",
        "                \"Use `layer(decoder_sequence, encoder_sequence)` to \"\n",
        "                \"build a layer with cross attention, or \"\n",
        "                \"`layer(decoder_sequence)` to build a layer without. \"\n",
        "                \"This layer has been built without cross attention, but \"\n",
        "                \"you are trying to call it with encoder_sequence.\"\n",
        "            )\n",
        "        elif is_cross_attention and not has_encoder_sequence:\n",
        "            raise ValueError(\n",
        "                \"The number of call arguments to \"\n",
        "                \"`keras_nlp.layers.TransformerDecoder` should not change. \"\n",
        "                \"Use `layer(decoder_sequence, encoder_sequence)` to \"\n",
        "                \"build a layer with cross attention, or \"\n",
        "                \"`layer(decoder_sequence)` to build a layer without. \"\n",
        "                \"This layer has been built with cross attention, but \"\n",
        "                \"you did not provide encoder_sequence.\"\n",
        "            )\n",
        "        decoder_mask = merge_padding_and_attention_mask(\n",
        "            decoder_sequence, decoder_padding_mask, decoder_attention_mask\n",
        "        )\n",
        "        causal_mask = tf.cast(\n",
        "            compute_causal_mask(decoder_sequence),\n",
        "            dtype=tf.int32,\n",
        "        )\n",
        "        if decoder_mask is None:\n",
        "            decoder_mask = causal_mask\n",
        "        else:\n",
        "            decoder_mask = tf.minimum(decoder_mask, causal_mask)\n",
        "\n",
        "        # Decoder input self-attention.\n",
        "        self_attended = self._self_attention_layer(\n",
        "            decoder_sequence,\n",
        "            decoder_sequence,\n",
        "            decoder_sequence,\n",
        "            attention_mask=decoder_mask,\n",
        "        )\n",
        "        self_attended = self._self_attention_dropout(self_attended)\n",
        "        attention_output = self._add_and_norm(\n",
        "            self_attended, decoder_sequence, self._decoder_attention_layernorm\n",
        "        )\n",
        "\n",
        "        if self._cross_attention_layer is not None:\n",
        "            encoder_mask = merge_padding_and_attention_mask(\n",
        "                encoder_sequence, encoder_padding_mask, encoder_attention_mask\n",
        "            )\n",
        "            # Cross attention.\n",
        "            cross_attended = self._cross_attention_layer(\n",
        "                query=attention_output,\n",
        "                value=encoder_sequence,\n",
        "                key=encoder_sequence,\n",
        "                attention_mask=encoder_mask,\n",
        "            )\n",
        "            cross_attended = self._cross_attention_dropout(\n",
        "                cross_attended,\n",
        "            )\n",
        "            attention_output = self._add_and_norm(\n",
        "                cross_attended,\n",
        "                attention_output,\n",
        "                self._cross_attention_layernorm,\n",
        "            )\n",
        "\n",
        "        # Feedforward.\n",
        "        feed_forward_output = self._feed_forward(attention_output)\n",
        "        return self._add_and_norm(\n",
        "            attention_output,\n",
        "            feed_forward_output,\n",
        "            self._feedforward_layernorm,\n",
        "        )\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"intermediate_dim\": self.intermediate_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "                \"dropout\": self.dropout,\n",
        "                \"activation\": keras.activations.serialize(self.activation),\n",
        "                \"layer_norm_epsilon\": self.layer_norm_epsilon,\n",
        "                \"kernel_initializer\": keras.initializers.serialize(\n",
        "                    self.kernel_initializer\n",
        "                ),\n",
        "                \"bias_initializer\": keras.initializers.serialize(\n",
        "                    self.bias_initializer\n",
        "                ),\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "\n",
        "x =TransformerDecoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n",
        "\n",
        "\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "decoder_outputs = keras.layers.Dense(len(tel_vocab), activation='sigmoid')(x)\n",
        "decoder = keras.Model(\n",
        "    [\n",
        "        decoder_inputs,\n",
        "        encoded_seq_inputs,\n",
        "    ],\n",
        "    decoder_outputs,\n",
        ")\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "\n",
        "transformer= keras.Model(\n",
        "    [encoder_inputs, decoder_inputs],\n",
        "    decoder_outputs,\n",
        "    name=\"transformer\",\n",
        ")\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfEfHW83giDR",
        "outputId": "148fc9dd-cae8-4210-c074-dd6c3194dd5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " token_and_position_embedding (  (None, None, 256)   3770368     ['encoder_inputs[0][0]']         \n",
            " TokenAndPositionEmbedding)                                                                       \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " transformer_encoder (Transform  (None, None, 256)   1315072     ['token_and_position_embedding[0]\n",
            " erEncoder)                                                      [0]']                            \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, None, 15000)  10195608    ['decoder_inputs[0][0]',         \n",
            "                                                                  'transformer_encoder[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 15,281,048\n",
            "Trainable params: 15,281,048\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.fit(whatsapp_ds_500,epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYZo4joretUL",
        "outputId": "5cbe8c62-9e64-47d8-f438-7cfcc6a38c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 15s 1s/step - loss: 8.2528 - accuracy: 0.2465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f162c103550>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "def _validate_prompt(prompt):\n",
        "    \"\"\"Helper function to validate input to text_generation utils.\"\"\"\n",
        "    if not isinstance(prompt, (tf.Tensor, tf.RaggedTensor)):\n",
        "        prompt = tf.convert_to_tensor(prompt)\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def _get_prompt_shape(prompt):\n",
        "    \"\"\"Helper function to get the batch size and prompt length.\"\"\"\n",
        "    if isinstance(prompt, tf.Tensor):\n",
        "        shape = tf.shape(prompt)\n",
        "        return (shape[0], shape[1])\n",
        "    elif isinstance(prompt, tf.RaggedTensor):\n",
        "        batch_size = prompt.nrows()\n",
        "        length = tf.math.reduce_min(tf.RaggedTensor.row_lengths(prompt))\n",
        "        return (batch_size, length)\n",
        "\n",
        "\n",
        "def _pad_prompt(prompt, max_length):\n",
        "    \"\"\"Pad prompt to `max_length` and compute a mask for controlled updates.\n",
        "    This utility will pad the (possibly ragged) prompt to `max_length`, and\n",
        "    compute a mask where the input was originally set in the prompt, to avoid\n",
        "    overwriting the original inputs when generating token(s) for the next\n",
        "    timestep.\n",
        "    \"\"\"\n",
        "    if isinstance(prompt, tf.Tensor):\n",
        "        shape = tf.shape(prompt)\n",
        "        extra_space = tf.math.maximum(0, max_length - shape[1])\n",
        "        pad_shape = [shape[0], extra_space]\n",
        "\n",
        "        mask = tf.ones(shape, tf.bool)\n",
        "        mask = tf.concat((mask, tf.zeros(pad_shape, tf.bool)), axis=1)\n",
        "        prompt = tf.concat((prompt, tf.zeros(pad_shape, prompt.dtype)), axis=1)\n",
        "    elif isinstance(prompt, tf.RaggedTensor):\n",
        "        # TODO: `to_tensor()` works with `jit_compile = True` in TF 2.8.x but\n",
        "        # fails in TF 2.9.x. Fix this. After this issue has been fixed, we can\n",
        "        # condense the two branches into one by starting off with a ragged tensor.\n",
        "        mask = tf.ones_like(prompt, dtype=tf.bool)\n",
        "        mask = mask.to_tensor(shape=(None, max_length))\n",
        "        prompt = prompt.to_tensor(shape=(None, max_length))\n",
        "    return prompt, mask\n",
        "\n",
        "\n",
        "def _validate_token_probability_fn(token_probability_fn, prompt):\n",
        "    \"\"\"Helper function to validate `token_probability_fn` output.\"\"\"\n",
        "    test_pred = token_probability_fn(prompt)\n",
        "    if len(test_pred.shape) != 2:\n",
        "        raise ValueError(\n",
        "            \"Output of `token_probability_fn` is not a 2D tensor, \"\n",
        "            \"please provide a function with the output shape \"\n",
        "            \"[batch_size, vocab_size].\"\n",
        "        )\n",
        "\n",
        "    return tf.shape(test_pred)[-1], test_pred.dtype\n",
        "\n",
        "\n",
        "def _mask_tokens_after_end_token(\n",
        "    prompt, max_length, end_token_id, pad_token_id\n",
        "):\n",
        "    \"\"\"Helper function to mask the tokens after the end token.\"\"\"\n",
        "    # Mask out tokens after `end_token_id` is encountered.\n",
        "    # Find index of first end_token_id.\n",
        "    end_indices = tf.math.argmax(prompt == end_token_id, -1)\n",
        "    # Use max_length if no `end_token_id` is found.\n",
        "    end_indices = tf.where(\n",
        "        end_indices == 0,\n",
        "        tf.cast(max_length, dtype=end_indices.dtype),\n",
        "        end_indices,\n",
        "    )\n",
        "    # Build a mask including end_token and replace tokens after end_token\n",
        "    # with `pad_token_id`.\n",
        "    valid_indices = tf.sequence_mask(end_indices + 1, maxlen=max_length)\n",
        "    return tf.where(valid_indices, prompt, pad_token_id)\n",
        "def beam_search(\n",
        "    token_probability_fn,\n",
        "    prompt,\n",
        "    max_length,\n",
        "    num_beams,\n",
        "    from_logits=False,\n",
        "    end_token_id=None,\n",
        "    pad_token_id=0,\n",
        "):\n",
        "    if num_beams <= 0:\n",
        "        raise ValueError(\n",
        "            f\"`num_beams` should be strictly positive. Received: `num_beams={num_beams}`.\"\n",
        "        )\n",
        "    # if num_beams == 1:\n",
        "    #     return greedy_search(\n",
        "    #         token_probability_fn=token_probability_fn,\n",
        "    #         prompt=prompt,\n",
        "    #         max_length=max_length,\n",
        "    #         end_token_id=end_token_id,\n",
        "    #         pad_token_id=pad_token_id,\n",
        "    #     )\n",
        "\n",
        "    prompt = _validate_prompt(prompt)\n",
        "\n",
        "    input_is_1d = prompt.shape.rank == 1\n",
        "    if input_is_1d:\n",
        "        prompt = prompt[tf.newaxis, :]\n",
        "\n",
        "    batch_size, length = _get_prompt_shape(prompt)\n",
        "    prompt, mask = _pad_prompt(prompt, max_length)\n",
        "\n",
        "    vocab_size, pred_dtype = _validate_token_probability_fn(\n",
        "        token_probability_fn, prompt\n",
        "    )\n",
        "\n",
        "    if length >= max_length:\n",
        "        return tf.squeeze(prompt) if input_is_1d else prompt\n",
        "\n",
        "    # Initialize beam with shape `(batch_size, num_beams, length)`.\n",
        "    beams = tf.repeat(tf.expand_dims(prompt, axis=1), num_beams, axis=1)\n",
        "\n",
        "    # Initialize `beams_prob` with shape `(batch_size, num_beams)`.\n",
        "    beams_prob = tf.zeros([batch_size, 1], dtype=pred_dtype)\n",
        "    beams_prob = tf.concat(\n",
        "        [beams_prob, tf.fill((batch_size, num_beams - 1), pred_dtype.min)],\n",
        "        axis=-1,\n",
        "    )\n",
        "\n",
        "    def one_step(beams, beams_prob, length):\n",
        "        truncated_beams = beams[..., :length]\n",
        "\n",
        "        flattened_beams = tf.reshape(\n",
        "            truncated_beams, shape=[batch_size * num_beams, -1]\n",
        "        )\n",
        "        preds = token_probability_fn(flattened_beams)\n",
        "        if from_logits:\n",
        "            preds = keras.activations.softmax(preds, axis=-1)\n",
        "        # Reshape `preds` to shape `(batch_size, num_beams * vocab_size)`.\n",
        "        preds = tf.reshape(preds, shape=[batch_size, -1])\n",
        "\n",
        "        probs = tf.math.log(preds) + tf.repeat(\n",
        "            beams_prob, repeats=vocab_size, axis=1\n",
        "        )\n",
        "\n",
        "        candidate_prob, candidate_indexes = tf.math.top_k(\n",
        "            probs, k=num_beams, sorted=False\n",
        "        )\n",
        "        candidate_beam_indexes = candidate_indexes // vocab_size\n",
        "        next_token = candidate_indexes % vocab_size\n",
        "\n",
        "        beams = tf.gather(beams, candidate_beam_indexes, axis=1, batch_dims=1)\n",
        "\n",
        "        # Build a new column of updates to scatter into the beam tensor.\n",
        "        next_token = tf.where(\n",
        "            condition=mask[..., length, tf.newaxis],\n",
        "            x=beams[..., length],\n",
        "            y=next_token,\n",
        "        )\n",
        "        next_token = tf.reshape(next_token, shape=[-1])\n",
        "\n",
        "        # Generate `(batch_index, beam_index)` tuples for each beam.\n",
        "        beam_indices = tf.where(tf.ones((batch_size, num_beams), tf.bool))\n",
        "        beam_indices = tf.cast(beam_indices, dtype=length.dtype)\n",
        "        # Build a tensor of repeated `length` values.\n",
        "        length_indices = tf.fill((batch_size * num_beams, 1), length)\n",
        "        # Concatenate to a triplet of `(batch_index, beam_index, length)`.\n",
        "        indices = tf.concat([beam_indices, length_indices], axis=-1)\n",
        "\n",
        "        # Update `beams[:, :, length]` with `next_token`.\n",
        "        beams = tf.tensor_scatter_nd_update(\n",
        "            tensor=beams,\n",
        "            indices=indices,\n",
        "            updates=next_token,\n",
        "        )\n",
        "\n",
        "        beams_prob = candidate_prob\n",
        "        length = tf.add(length, 1)\n",
        "\n",
        "        return beams, beams_prob, length\n",
        "\n",
        "    # Run a while loop till text of length `max_length` has been generated.\n",
        "    beams, beams_prob, length = tf.while_loop(\n",
        "        cond=lambda beams, beams_prob, length: tf.less(length, max_length),\n",
        "        body=one_step,\n",
        "        loop_vars=(beams, beams_prob, length),\n",
        "    )\n",
        "\n",
        "    # Get the beam with the maximum probability.\n",
        "    max_indexes = tf.math.argmax(beams_prob, axis=-1)\n",
        "    max_beams = tf.gather(\n",
        "        beams, max_indexes[:, tf.newaxis], axis=1, batch_dims=1\n",
        "    )\n",
        "    prompt = tf.squeeze(max_beams)\n",
        "\n",
        "    if end_token_id is not None:\n",
        "        prompt = _mask_tokens_after_end_token(\n",
        "            prompt, max_length, end_token_id, pad_token_id\n",
        "        )\n",
        "    return tf.squeeze(prompt) if input_is_1d else prompt\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zHOX4PkgcJol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import MultiHeadAttention\n",
        "\n",
        "num_heads = 4\n",
        "key_dim = 64\n",
        "value_dim = 64\n",
        "\n",
        "# Example input shapes\n",
        "batch_size = 32\n",
        "query_seq_len = 16\n",
        "value_seq_len = 32\n",
        "embedding_size = 128\n",
        "\n",
        "# Create the MultiHeadAttention layer with the desired key shape\n",
        "mha_layer = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, value_dim=value_dim)\n",
        "\n",
        "# Create example input tensors\n",
        "query = tf.random.normal((batch_size, query_seq_len, embedding_size))\n",
        "value = tf.random.normal((batch_size, value_seq_len, embedding_size))\n",
        "\n",
        "# Call the layer with the inputs\n",
        "output = mha_layer(query, value)\n"
      ],
      "metadata": {
        "id": "cySuEEeirUC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def decode_sequences__4(input_sentences):\n",
        "    batch_size = tf.shape(input_sentences)[0]\n",
        "\n",
        "    # Tokenize the encoder input.\n",
        "    encoder_input_tokens = eng_tokenizer(input_sentences).to_tensor(shape=(None, 10))\n",
        "    def token_probability_fn(decoder_input_tokens):\n",
        "        return transformer([encoder_input_tokens, decoder_input_tokens])[:, -1, :]\n",
        "\n",
        "    # Set the prompt to the \"[START]\" token.\n",
        "    prompt = tf.fill((batch_size, 1), spa_tokenizer.token_to_id(\"[START]\"))\n",
        "\n",
        "    generated_tokens = beam_search(\n",
        "        token_probability_fn,\n",
        "        prompt,\n",
        "        max_length=10,\n",
        "        num_beams=4,\n",
        "        end_token_id=spa_tokenizer.token_to_id(\"[END]\"),\n",
        "    )\n",
        "    generated_sentences = spa_tokenizer.detokenize(generated_tokens)\n",
        "    return generated_sentences\n",
        "decode_sequences__4(tf.constant(['stars'])).numpy()[0].decode(\"utf-8\").replace(\"[PAD]\", \"\").replace(\"[START]\", \"\").replace(\"[END]\", \"\").strip()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "7w9uQhBtnA1h",
        "outputId": "3fe1a80e-771c-4f0d-bcd1-2037f6476db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-007bcd15ff2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mgenerated_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspa_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgenerated_sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdecode_sequences__4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[PAD]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[START]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[END]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-007bcd15ff2f>\u001b[0m in \u001b[0;36mdecode_sequences__4\u001b[0;34m(input_sentences)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspa_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[START]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     generated_tokens = beam_search(\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtoken_probability_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-9bd72a9d8202>\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(token_probability_fn, prompt, max_length, num_beams, from_logits, end_token_id, pad_token_id)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# Run a while loop till text of length `max_length` has been generated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     beams, beams_prob, length = tf.while_loop(\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mbeams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeams_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2515\u001b[0m   \"\"\"\n\u001b[0;32m-> 2516\u001b[0;31m   return while_loop(\n\u001b[0m\u001b[1;32m   2517\u001b[0m       \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m       \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2763\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2764\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2765\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2767\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-9bd72a9d8202>\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(beams, beams_prob, length)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mtruncated_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         )\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_probability_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_beams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-007bcd15ff2f>\u001b[0m in \u001b[0;36mtoken_probability_fn\u001b[0;34m(decoder_input_tokens)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mencoder_input_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoken_probability_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Set the prompt to the \"[START]\" token.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-70b41b1da7c1>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, decoder_sequence, encoder_sequence, decoder_padding_mask, decoder_attention_mask, encoder_padding_mask, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    258\u001b[0m             )\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# Cross attention.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             cross_attended = self._cross_attention_layer(\n\u001b[0m\u001b[1;32m    261\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_sequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-f5390b17c018>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, value, key, attention_mask, return_attention_scores, training, use_causal_mask)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         attention_output, attention_scores = self._compute_attention(\n\u001b[0m\u001b[1;32m    429\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-21-f5390b17c018>\u001b[0m in \u001b[0;36m_compute_attention\u001b[0;34m(self, query, key, value, attention_mask, training)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dot_product_equation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         attention_scores = self._masked_softmax(\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'multi_head_attention_1' (type MultiHeadAttention).\n\n{{function_node __wrapped__Einsum_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Expected dimension 1 at axis 0 of the input shaped [4,1,8,32] but got dimension 4 [Op:Einsum]\n\nCall arguments received by layer 'multi_head_attention_1' (type MultiHeadAttention):\n  • query=tf.Tensor(shape=(4, 1, 256), dtype=float32)\n  • value=tf.Tensor(shape=(1, 10, 256), dtype=float32)\n  • key=tf.Tensor(shape=(1, 10, 256), dtype=float32)\n  • attention_mask=tf.Tensor(shape=(1, 1, 10), dtype=int32)\n  • return_attention_scores=False\n  • training=None\n  • use_causal_mask=False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WFbnJtBJosC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3H-2meUr1S9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}